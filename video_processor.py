#!/usr/bin/env python3
"""
–õ–æ–∫–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –¥–ª—è Final Cut Pro
–ê–Ω–∞–ª–æ–≥ Gling.ai - —É–¥–∞–ª–µ–Ω–∏–µ –ø–∞—É–∑ + –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã
"""

import os
import json
import subprocess
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple
import tempfile


@dataclass
class Segment:
    """–°–µ–≥–º–µ–Ω—Ç –≤–∏–¥–µ–æ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏"""
    start: float  # —Å–µ–∫—É–Ω–¥—ã
    end: float    # —Å–µ–∫—É–Ω–¥—ã
    is_speech: bool  # True –µ—Å–ª–∏ —Ä–µ—á—å, False –µ—Å–ª–∏ –ø–∞—É–∑–∞


class VideoProcessor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""

    def __init__(self, silence_threshold_db: float = -35, min_silence_duration: float = 0.5):
        """
        Args:
            silence_threshold_db: –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –≤ dB (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é -35)
            min_silence_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—É–∑—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)
        """
        self.silence_threshold = silence_threshold_db
        self.min_silence_duration = min_silence_duration

    def detect_silences(self, video_path: str) -> List[Tuple[float, float]]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–∞—É–∑—ã –≤ –≤–∏–¥–µ–æ –∏—Å–ø–æ–ª—å–∑—É—è ffmpeg

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (start_time, end_time) –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—É–∑—ã
        """
        print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∞—É–¥–∏–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—É–∑...")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg silencedetect —Ñ–∏–ª—å—Ç—Ä
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-af', f'silencedetect=noise={self.silence_threshold}dB:d={self.min_silence_duration}',
            '-f', 'null',
            '-'
        ]

        result = subprocess.run(
            cmd,
            stderr=subprocess.PIPE,
            stdout=subprocess.PIPE,
            text=True
        )

        # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ ffmpeg
        silences = []
        silence_start = None

        for line in result.stderr.split('\n'):
            if 'silence_start:' in line:
                silence_start = float(line.split('silence_start:')[1].strip())
            elif 'silence_end:' in line and silence_start is not None:
                silence_end = float(line.split('silence_end:')[1].split('|')[0].strip())
                silences.append((silence_start, silence_end))
                silence_start = None

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–∞—É–∑: {len(silences)}")
        return silences

    def get_video_duration(self, video_path: str) -> float:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ"""
        cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            video_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        return float(result.stdout.strip())

    def create_segments(self, video_duration: float, silences: List[Tuple[float, float]]) -> List[Segment]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Ä–µ—á–∏ –∏ –ø–∞—É–∑

        Args:
            video_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ
            silences: –°–ø–∏—Å–æ–∫ –ø–∞—É–∑

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        segments = []
        current_time = 0

        for silence_start, silence_end in silences:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—á–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç –ø–µ—Ä–µ–¥ –ø–∞—É–∑–æ–π
            if silence_start > current_time:
                segments.append(Segment(
                    start=current_time,
                    end=silence_start,
                    is_speech=True
                ))

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É
            segments.append(Segment(
                start=silence_start,
                end=silence_end,
                is_speech=False
            ))

            current_time = silence_end

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ—á–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç
        if current_time < video_duration:
            segments.append(Segment(
                start=current_time,
                end=video_duration,
                is_speech=True
            ))

        return segments

    def remove_silences(self, video_path: str, output_path: str, segments: List[Segment]) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç –ø–∞—É–∑—ã –∏–∑ –≤–∏–¥–µ–æ –∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —Ñ–∞–π–ª

        Args:
            video_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤

        Returns:
            –ü—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ
        """
        print("‚úÇÔ∏è  –£–¥–∞–ª—è—é –ø–∞—É–∑—ã –∏–∑ –≤–∏–¥–µ–æ...")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ—á–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        speech_segments = [s for s in segments if s.is_speech]

        if not speech_segments:
            print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤!")
            return video_path

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
        temp_dir = tempfile.mkdtemp()
        concat_file = os.path.join(temp_dir, 'concat_list.txt')
        segment_files = []

        # –í—ã—Ä–µ–∑–∞–µ–º –∫–∞–∂–¥—ã–π —Ä–µ—á–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç
        for i, seg in enumerate(speech_segments):
            segment_path = os.path.join(temp_dir, f'segment_{i:04d}.mp4')
            segment_files.append(segment_path)

            duration = seg.end - seg.start

            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-ss', str(seg.start),
                '-t', str(duration),
                '-c', 'copy',
                '-y',
                segment_path
            ]

            subprocess.run(cmd, capture_output=True)

        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
        with open(concat_file, 'w') as f:
            for seg_file in segment_files:
                f.write(f"file '{seg_file}'\n")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        cmd = [
            'ffmpeg',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c', 'copy',
            '-y',
            output_path
        ]

        subprocess.run(cmd, capture_output=True)

        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for seg_file in segment_files:
            try:
                os.remove(seg_file)
            except:
                pass
        try:
            os.remove(concat_file)
            os.rmdir(temp_dir)
        except:
            pass

        print(f"‚úÖ –í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {output_path}")
        return output_path

    def process_video(self, video_path: str, output_dir: str = None) -> dict:
        """
        –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: –∞–Ω–∞–ª–∏–∑ –ø–∞—É–∑ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏

        Args:
            video_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ç–∞ –∂–µ —á—Ç–æ –∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        video_path = os.path.abspath(video_path)

        if output_dir is None:
            output_dir = os.path.dirname(video_path)

        # –°–æ–∑–¥–∞–µ–º –∏–º—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        base_name = Path(video_path).stem
        output_video = os.path.join(output_dir, f"{base_name}_edited.mp4")

        # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = self.get_video_duration(video_path)

        # –ù–∞—Ö–æ–¥–∏–º –ø–∞—É–∑—ã
        silences = self.detect_silences(video_path)

        # –°–æ–∑–¥–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = self.create_segments(duration, silences)

        # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_silence = sum(s.end - s.start for s in segments if not s.is_speech)
        total_speech = sum(s.end - s.start for s in segments if s.is_speech)

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –ò—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f}—Å")
        print(f"   –†–µ—á—å: {total_speech:.1f}—Å ({total_speech/duration*100:.1f}%)")
        print(f"   –ü–∞—É–∑—ã: {total_silence:.1f}—Å ({total_silence/duration*100:.1f}%)")
        print(f"   –ù–æ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_speech:.1f}—Å")
        print(f"   –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏: {total_silence:.1f}—Å\n")

        # –£–¥–∞–ª—è–µ–º –ø–∞—É–∑—ã
        edited_video = self.remove_silences(video_path, output_video, segments)

        return {
            'original_video': video_path,
            'edited_video': edited_video,
            'segments': segments,
            'statistics': {
                'original_duration': duration,
                'speech_duration': total_speech,
                'silence_duration': total_silence,
                'silences_removed': len([s for s in segments if not s.is_speech])
            }
        }


if __name__ == '__main__':
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    import sys

    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python video_processor.py <–ø—É—Ç—å_–∫_–≤–∏–¥–µ–æ>")
        sys.exit(1)

    video_path = sys.argv[1]
    processor = VideoProcessor(silence_threshold_db=-35, min_silence_duration=0.5)
    result = processor.process_video(video_path)

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: {result['edited_video']}")
